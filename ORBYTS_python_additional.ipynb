{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgeAEim56vd2fK/pUcENpM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinarhianna/python-tutorials/blob/main/ORBYTS_python_additional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Experiment ðŸ§ª\n",
        "\n",
        "\n",
        "*   This notebook lets you explore how small changes to a CNN affects its learning.\n",
        "*   We will start with a working CNN, and then make one change at a time.\n",
        "\n",
        "Run each cell, and confirm that our CNN works properly.\n"
      ],
      "metadata": {
        "id": "HmLXqdteWLk1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "slIIjzT5V0Ns"
      },
      "outputs": [],
      "source": [
        "# import our modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Preparation"
      ],
      "metadata": {
        "id": "c1Vh3yIUc1LI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will make up some data to train and test our network on. Our dataset will consist of 3 classes:\n",
        "* Sine wave (Class 0)\n",
        "* Square wave (Class 1)\n",
        "* Random noise (Class 2)\n",
        "\n",
        "If you're interested, read through the code and have a think how it might work to generate data. If you're not, just run it!"
      ],
      "metadata": {
        "id": "omgNEnqbXSO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class = 20\n",
        "length = 5000\n",
        "\n",
        "# Class 0: Sine wave\n",
        "sine_curves = [np.sin(np.linspace(0, np.pi * np.random.uniform(4, 8), length)) + np.random.normal(0, 0.1, length)\n",
        "               for _ in range(num_samples_per_class)]\n",
        "\n",
        "# Class 1: Square wave\n",
        "square_curves = [np.sign(np.sin(np.linspace(0, np.pi * np.random.uniform(4, 8), length))) + np.random.normal(0, 0.1, length)\n",
        "                 for _ in range(num_samples_per_class)]\n",
        "\n",
        "# Class 2: Random noise\n",
        "noise_curves = [np.random.normal(0, 1, length) for _ in range(num_samples_per_class)]\n"
      ],
      "metadata": {
        "id": "y0pc1xk2XH1e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below does all of the data preparation for it to be suitable for training and testing a CNN. Again, don't worry if it doesn't make sense to you, but if you're curious what it is doing, have a read or ask Marina how it works."
      ],
      "metadata": {
        "id": "uNFth2QecB6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack and label\n",
        "X = np.stack(sine_curves + square_curves + noise_curves)\n",
        "y = np.array([0]*num_samples_per_class + [1]*num_samples_per_class + [2]*num_samples_per_class)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Convert to tensors and reshape for CNN (N, 1, 5000)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Dataset and DataLoader\n",
        "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=16)"
      ],
      "metadata": {
        "id": "f3DSWR3QatTX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's have a look at what our data looks like."
      ],
      "metadata": {
        "id": "_kHgRy8VckbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Š Plot one example from each class\n",
        "for class_label in range(3):\n",
        "    idx = np.where(y_train == class_label)[0][0]\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    plt.plot(X_train[idx])\n",
        "    plt.title(f\"Example from Class {class_label}\")\n",
        "    plt.xlabel(\"Time step\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XRPJ0lODauTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Training and Testing our CNN"
      ],
      "metadata": {
        "id": "Pm7z8QhCcwgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§  Base CNN Model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(16 * 2500, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "rbqcqsLua2l7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸš‚ Training Loop\n",
        "def train_model():\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = loss_fn(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # ðŸ§ª Evaluate\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in test_dl:\n",
        "                preds = model(xb)\n",
        "                predicted = torch.argmax(preds, dim=1)\n",
        "                correct += (predicted == yb).sum().item()\n",
        "                total += yb.size(0)\n",
        "        test_accuracies.append(correct / total)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}, Test Accuracy = {correct/total:.2f}\")\n",
        "\n",
        "    plt.plot(test_accuracies)\n",
        "    plt.title(\"Test Accuracy over Epochs\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "train_model()"
      ],
      "metadata": {
        "id": "B6bwVQoQa9VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHALLENGE\n",
        "Implement each of the changes below 1 at a time, and re-run the cells starting from Section 2 (the cell starting with `# ðŸ§  Base CNN Model`).\n",
        "\n",
        "For each change, tell Marina what you observe and why you think it happens.\n",
        "\n",
        "If it makes the accuracy **worse**, change it back before you go on to the next checklist. If it makes it **better**, keep the change!\n",
        "\n",
        "### ðŸ“œ EXPERIMENT CHECKLIST\n",
        "1. Increase the size of the dataset. Right now it is 20, so try 50 and 100 and see what happens.\n",
        "2. Change `Conv1d` kernel size to 9. What happens to the accuracy?\n",
        "3. Remove the `MaxPool1d` layer. Does it still learn?\n",
        "4. Change the learning rate to `0.01` or `0.0001`.\n",
        "5. Right now our dataset is split so training is 80% and testing is 20%. Change the split so training data is 20% and testing is 80%. What happens?\n",
        "6. Increase number of `epochs` from 5 to 20. Does the model improve more?\n",
        "7. Try `batch size = 4` vs. `batch size = 64`. How does training speed and accuracy change?\n",
        "8. Change activation function to `nn.Tanh` instead of `nn.ReLU` â€“ what happens?\n",
        "9. **Hard:** Add a second convolutional layer to the CNN, with an input of 16 and an output of 32. Does it improve accuracy or overfit?\n",
        "10. **Extra hard:** Add a dropout layer `(nn.Dropout(0.3))` after ReLU. Does accuracy change?\n",
        "\n"
      ],
      "metadata": {
        "id": "WZZ-qxRxc_DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Example code for 9.\n",
        "\n",
        "# Inside SimpleCNN(), add this line after self.conv1\n",
        "self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
        "\n",
        "# Inside the forward pass, add these lines after x = self.conv1(x)\n",
        "x = self.conv2(x)\n",
        "x = torch.relu(x)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_2GoxKRIl49F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Example code for 10.\n",
        "\n",
        "# Inside SimpleCNN(), add this line\n",
        "self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "# Inside the forward pass, add this line just before x = self.pool(x)\n",
        "x = self.dropout(x)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zeQg_9ZonyS_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}